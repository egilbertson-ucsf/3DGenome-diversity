{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "247e8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tskit\n",
    "import json\n",
    "import pandas as pd\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f0ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/wynton/group/capra/projects/modern_human_3Dgenome/data/tree_sequences/tree_files'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c179afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ee7a8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr10_ancestral_variants.tsv\r\n",
      "chr11_ancestral_variants.tsv\r\n",
      "chr12_ancestral_variants.tsv\r\n",
      "chr13_ancestral_variants.tsv\r\n",
      "chr14_ancestral_variants.tsv\r\n",
      "chr15_ancestral_variants.tsv\r\n",
      "chr16_ancestral_variants.tsv\r\n",
      "chr17_ancestral_variants.tsv\r\n",
      "chr18_ancestral_variants.tsv\r\n",
      "chr19_ancestral_variants.tsv\r\n",
      "chr1_ancestral_variants.tsv\r\n",
      "chr20_ancestral_variants.tsv\r\n",
      "chr21_ancestral_variants.tsv\r\n",
      "chr22_ancestral_variants.tsv\r\n",
      "chr2_ancestral_variants.tsv\r\n",
      "chr3_ancestral_variants.tsv\r\n",
      "chr4_ancestral_variants.tsv\r\n",
      "chr5_ancestral_variants.tsv\r\n",
      "chr6_ancestral_variants.tsv\r\n",
      "chr7_ancestral_variants.tsv\r\n",
      "chr8_ancestral_variants.tsv\r\n",
      "chr9_ancestral_variants.tsv\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr10_p.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr10_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr11_p.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr11_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr12_p.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr12_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr13_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr14_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr15_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr16_p.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr16_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr17_p.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr17_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr18_p.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr18_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr19_p.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr19_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr1_p.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr1_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr20_p.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr20_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr21_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr22_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr2_p.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr2_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr3_p.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr3_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr4_p.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr4_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr5_p.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr5_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr6_p.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr6_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr7_p.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr7_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr8_p.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr8_q.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr9_p.dated.trees\r\n",
      "hgdp_tgp_sgdp_high_cov_ancients_chr9_q.dated.trees\r\n"
     ]
    }
   ],
   "source": [
    "!ls $DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25470d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variant_files(chrm):\n",
    "    p = \"%s/hgdp_tgp_sgdp_high_cov_ancients_%s_p.dated.trees\" % (DATA_PATH,chrm)\n",
    "    p_exists = False\n",
    "    if os.path.exists(p):\n",
    "        print(\"loading p arm of %s\" % chrm)\n",
    "        p_exists = True\n",
    "        tsp = tskit.load(p)\n",
    "        tsp\n",
    "    else:\n",
    "        print(\"ATTENTION: p arm of %s does not have tree file\" % chrm)\n",
    "\n",
    "    q = \"%s/hgdp_tgp_sgdp_high_cov_ancients_%s_q.dated.trees\" % (DATA_PATH,chrm)\n",
    "    q_exists = False\n",
    "    if os.path.exists(q):\n",
    "        print(\"loading q arm of %s\" % chrm)\n",
    "        q_exists = True\n",
    "        tsq = tskit.load(q)\n",
    "        tsq\n",
    "    else:\n",
    "        print(\"ATTENTION: q arm of %s does not have tree file\" % chrm)\n",
    "    anc_alleles = [('chr','position','ancestral_state','reference','rsid')]\n",
    "    p_len=0\n",
    "    q_len=0\n",
    "    if (p_exists) and (q_exists) and (tsp.sites()[len(tsp.sites())-1].position < tsq.sites()[0].position):\n",
    "        print(\"extracting ancestral states, both p and q\")\n",
    "        for site in tsp.sites():\n",
    "            anc_state = site.ancestral_state\n",
    "            m = json.loads(site.metadata)\n",
    "            ref_state = m[\"REF\"]\n",
    "            rsid = m[\"ID\"]\n",
    "            pos = int(site.position)\n",
    "            anc_alleles.append((chrm, pos,anc_state, ref_state, rsid))\n",
    "            p_len +=1\n",
    "\n",
    "        for site in tsq.sites():\n",
    "            anc_state = site.ancestral_state\n",
    "            m = json.loads(site.metadata)\n",
    "            ref_state = m[\"REF\"]\n",
    "            rsid = m[\"ID\"]\n",
    "            pos = int(site.position)\n",
    "            anc_alleles.append((chrm, pos,anc_state, ref_state, rsid))\n",
    "            q_len +=1\n",
    "    elif p_exists and not q_exists:\n",
    "        print(\"extracting ancestral states p\")\n",
    "        for site in tsp.sites():\n",
    "            anc_state = site.ancestral_state\n",
    "            m = json.loads(site.metadata)\n",
    "            ref_state = m[\"REF\"]\n",
    "            rsid = m[\"ID\"]\n",
    "            pos = int(site.position)\n",
    "            anc_alleles.append((chrm, pos,anc_state, ref_state, rsid))\n",
    "            p_len +=1\n",
    "    elif q_exists and not p_exists:\n",
    "        print(\"extracting ancestral states q\")\n",
    "        for site in tsq.sites():\n",
    "            anc_state = site.ancestral_state\n",
    "            m = json.loads(site.metadata)\n",
    "            ref_state = m[\"REF\"]\n",
    "            rsid = m[\"ID\"]\n",
    "            pos = int(site.position)\n",
    "            anc_alleles.append((chrm, pos,anc_state, ref_state, rsid))\n",
    "            q_len +=1\n",
    "    else:\n",
    "        print(\"ATTENTION: last site in p arm is not less than first site in q arm, or both files don't exist\")\n",
    "    if (p_len + q_len + 1 == len(anc_alleles)):\n",
    "        print(\"writing file\")\n",
    "        a = pd.DataFrame(anc_alleles)\n",
    "        a.to_csv('%s/%s_ancestral_variants.tsv' % (DATA_PATH, chrm), header=False, index=False, sep='\\t')\n",
    "    else:\n",
    "        print(\"ATTENTION: length of ancestral alleles does not match number of sites\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e77f325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading p arm of chr1\n",
      "loading q arm of chr1\n",
      "extracting ancestral states, both p and q\n",
      "writing file\n",
      "loading p arm of chr2\n",
      "loading q arm of chr2\n",
      "extracting ancestral states, both p and q\n",
      "writing file\n",
      "loading p arm of chr3\n",
      "loading q arm of chr3\n",
      "extracting ancestral states, both p and q\n",
      "writing file\n",
      "loading p arm of chr4\n",
      "loading q arm of chr4\n",
      "extracting ancestral states, both p and q\n",
      "writing file\n",
      "loading p arm of chr5\n",
      "loading q arm of chr5\n",
      "extracting ancestral states, both p and q\n",
      "writing file\n",
      "loading p arm of chr6\n",
      "loading q arm of chr6\n",
      "extracting ancestral states, both p and q\n",
      "writing file\n",
      "loading p arm of chr7\n",
      "loading q arm of chr7\n",
      "extracting ancestral states, both p and q\n",
      "writing file\n",
      "loading p arm of chr8\n",
      "loading q arm of chr8\n",
      "extracting ancestral states, both p and q\n",
      "writing file\n",
      "loading p arm of chr9\n",
      "loading q arm of chr9\n",
      "extracting ancestral states, both p and q\n",
      "writing file\n",
      "loading p arm of chr10\n",
      "loading q arm of chr10\n",
      "extracting ancestral states, both p and q\n",
      "writing file\n",
      "loading p arm of chr11\n",
      "loading q arm of chr11\n",
      "extracting ancestral states, both p and q\n",
      "writing file\n",
      "loading p arm of chr12\n",
      "loading q arm of chr12\n",
      "extracting ancestral states, both p and q\n",
      "writing file\n",
      "ATTENTION: p arm of chr13 does not have tree file\n",
      "loading q arm of chr13\n",
      "extracting ancestral states q\n",
      "writing file\n",
      "ATTENTION: p arm of chr14 does not have tree file\n",
      "loading q arm of chr14\n",
      "extracting ancestral states q\n",
      "writing file\n",
      "ATTENTION: p arm of chr15 does not have tree file\n",
      "loading q arm of chr15\n",
      "extracting ancestral states q\n",
      "writing file\n",
      "loading p arm of chr16\n",
      "loading q arm of chr16\n",
      "extracting ancestral states, both p and q\n",
      "writing file\n",
      "loading p arm of chr17\n",
      "loading q arm of chr17\n",
      "extracting ancestral states, both p and q\n",
      "writing file\n",
      "loading p arm of chr18\n",
      "loading q arm of chr18\n",
      "extracting ancestral states, both p and q\n",
      "writing file\n",
      "loading p arm of chr19\n",
      "loading q arm of chr19\n",
      "extracting ancestral states, both p and q\n",
      "writing file\n",
      "loading p arm of chr20\n",
      "loading q arm of chr20\n",
      "extracting ancestral states, both p and q\n",
      "writing file\n",
      "ATTENTION: p arm of chr21 does not have tree file\n",
      "loading q arm of chr21\n",
      "extracting ancestral states q\n",
      "writing file\n",
      "ATTENTION: p arm of chr22 does not have tree file\n",
      "loading q arm of chr22\n",
      "extracting ancestral states q\n",
      "writing file\n"
     ]
    }
   ],
   "source": [
    "chrms = ['chr1','chr2','chr3','chr4','chr5','chr6','chr7','chr8','chr9','chr10','chr11','chr12','chr13','chr14','chr15','chr16','chr17','chr18','chr19','chr20','chr21','chr22']\n",
    "\n",
    "for chrm in chrms:\n",
    "    create_variant_files(chrm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee72e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea2f233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b81c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fasta(vp, fp, op, ss):\n",
    "\n",
    "    # make dictionary of variants\n",
    "    dict = {}\n",
    "    with open(vp, 'r') as calls:\n",
    "        for site in calls:\n",
    "            site = site.split()\n",
    "            if site[1] != 'position':\n",
    "                dict[int(site[1])] = site[2]\n",
    "\n",
    "    # write reference sequence with ancestral calls present in the dictionary\n",
    "    with open(f'{fp}', 'r') as fasta, open(f'{op}', 'w') as out:\n",
    "        lines = [ line.strip() for line in fasta ]\n",
    "        header = lines[0]\n",
    "        print(header, file = out)\n",
    "        no_header = lines[1:]\n",
    "        seq = ''.join(no_header)\n",
    "\n",
    "        for p, b in enumerate(seq, start=1):\n",
    "            if p in dict:\n",
    "                print(dict[p], end = \"\", file = out)\n",
    "            else:\n",
    "                print(b, end = \"\", file = out)\n",
    "\n",
    "    # read in output file to split the new sequence every nth base and rewrite output\t\t\t\n",
    "    with open(f'{op}', 'r') as out:\n",
    "        lines = [ line.strip() for line in out ]\n",
    "        header = lines[0]\n",
    "        no_header = lines[1]\n",
    "        seq = ''.join(no_header)\n",
    "\n",
    "        new_seq = ''\n",
    "        for i, bp in enumerate(seq):\n",
    "            if i % ss == 0:\n",
    "                new_seq += '\\n'\n",
    "            new_seq += bp\n",
    "\n",
    "        new_seq = new_seq[1:]\n",
    "\n",
    "    with open(f'{op}', 'w') as out:\n",
    "        print(header, file = out)\n",
    "        print(new_seq, file = out) \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4bb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff0498b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b9dbf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrms = ['chr1','chr2','chr3','chr4','chr5','chr6','chr7','chr8','chr9','chr10','chr11','chr12','chr13','chr14','chr15','chr16','chr17','chr18','chr19','chr20','chr21','chr22']\n",
    "PYSCRIPT = '/wynton/group/capra/projects/modern_human_3Dgenome/scripts/add_variants_to_FASTA.py'\n",
    "FASTA_PATH = '/wynton/home/capra/egilbertson/data/human_genome/chrms'\n",
    "OUT_PATH = '/wynton/group/capra/projects/modern_human_3Dgenome/data/genomes/human_archaic_ancestor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7f8523b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\n",
      "chr2\n",
      "chr3\n",
      "chr4\n",
      "chr5\n",
      "chr6\n",
      "chr7\n",
      "chr8\n",
      "chr9\n",
      "chr10\n",
      "chr11\n",
      "chr12\n",
      "chr13\n",
      "chr14\n",
      "chr15\n",
      "chr16\n",
      "chr17\n",
      "chr18\n",
      "chr19\n",
      "chr20\n",
      "chr21\n",
      "chr22\n"
     ]
    }
   ],
   "source": [
    "for chrm in chrms:\n",
    "    print(chrm)\n",
    "    var_path = '%s/%s_ancestral_variants.tsv' % (DATA_PATH, chrm)\n",
    "    output = '%s/human_archaic_ancestor_in_hg38_%s.fasta' % (OUT_PATH, chrm)\n",
    "    fasta = '%s/%s.fa' % (FASTA_PATH, chrm)\n",
    "    make_fasta(var_path, fasta, output, 50)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b1eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
